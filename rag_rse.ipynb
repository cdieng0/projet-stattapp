{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdc9ac09-d735-4a63-8565-3809696515d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymupdf\n",
      "Successfully installed pymupdf-1.25.5\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.10.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /opt/conda/lib/python3.12/site-packages (from faiss-cpu) (2.2.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from faiss-cpu) (24.2)\n",
      "Downloading faiss_cpu-1.10.0-cp312-cp312-manylinux_2_28_x86_64.whl (30.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.10.0\n",
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-4.0.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence_transformers)\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from sentence_transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence_transformers)\n",
      "  Downloading torch-2.6.0-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (from sentence_transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.12/site-packages (from sentence_transformers) (1.15.2)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence_transformers)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.12/site-packages (from sentence_transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/lib/python3.12/site-packages (from sentence_transformers) (4.13.2)\n",
      "Collecting filelock (from huggingface-hub>=0.20.0->sentence_transformers)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading triton-3.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (75.8.2)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence_transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.2.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2025.1.31)\n",
      "Downloading sentence_transformers-4.0.2-py3-none-any.whl (340 kB)\n",
      "Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading torch-2.6.0-cp312-cp312-manylinux1_x86_64.whl (766.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.6/766.6 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, mpmath, sympy, safetensors, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, filelock, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, torch, sentence_transformers\n",
      "Successfully installed filelock-3.18.0 huggingface-hub-0.30.2 mpmath-1.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 safetensors-0.5.3 sentence_transformers-4.0.2 sympy-1.13.1 tokenizers-0.21.1 torch-2.6.0 transformers-4.51.3 triton-3.2.0\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.12/site-packages (11.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf\n",
    "!pip install faiss-cpu\n",
    "!pip install sentence_transformers\n",
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "415641a6-776d-467f-806b-15b2b6928a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "KeyboardInterrupt\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/pip\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/pip/_internal/cli/main.py\", line 80, in main\n",
      "    return command.main(cmd_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/pip/_internal/cli/base_command.py\", line 157, in main\n",
      "    with self.main_context():\n",
      "         ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/contextlib.py\", line 144, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/pip/_internal/cli/command_context.py\", line 19, in main_context\n",
      "    with self._main_context:\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/contextlib.py\", line 610, in __exit__\n",
      "    raise exc_details[1]\n",
      "  File \"/opt/conda/lib/python3.12/contextlib.py\", line 595, in __exit__\n",
      "    if cb(*exc_details):\n",
      "       ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/contextlib.py\", line 144, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/pip/_internal/utils/temp_dir.py\", line 42, in global_tempdir_manager\n",
      "    with ExitStack() as stack:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/contextlib.py\", line 610, in __exit__\n",
      "    raise exc_details[1]\n",
      "  File \"/opt/conda/lib/python3.12/contextlib.py\", line 595, in __exit__\n",
      "    if cb(*exc_details):\n",
      "       ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/pip/_internal/utils/temp_dir.py\", line 169, in __exit__\n",
      "    self.cleanup()\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/pip/_internal/utils/temp_dir.py\", line 212, in cleanup\n",
      "    rmtree(self._path, ignore_errors=False)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/pip/_internal/utils/retry.py\", line 34, in retry_wrapped\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/pip/_internal/utils/misc.py\", line 136, in rmtree\n",
      "    shutil.rmtree(dir, onexc=handler)  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/shutil.py\", line 759, in rmtree\n",
      "    _rmtree_safe_fd(stack, onexc)\n",
      "  File \"/opt/conda/lib/python3.12/shutil.py\", line 698, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/IPython/core/async_helpers.py:128\u001b[39m, in \u001b[36m_pseudo_sync_runner\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[33;03mA runner that does not really allow async execution, and just advance the coroutine.\u001b[39;00m\n\u001b[32m    122\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    125\u001b[39m \u001b[33;03mCredit to Nathaniel Smith\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3381\u001b[39m, in \u001b[36mInteractiveShell.run_cell_async\u001b[39m\u001b[34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001b[39m\n\u001b[32m   3377\u001b[39m exec_count = \u001b[38;5;28mself\u001b[39m.execution_count\n\u001b[32m   3378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.error_in_exec:\n\u001b[32m   3379\u001b[39m     \u001b[38;5;66;03m# Store formatted traceback and error details\u001b[39;00m\n\u001b[32m   3380\u001b[39m     \u001b[38;5;28mself\u001b[39m.history_manager.exceptions[exec_count] = (\n\u001b[32m-> \u001b[39m\u001b[32m3381\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_exception_for_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror_in_exec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3382\u001b[39m     )\n\u001b[32m   3384\u001b[39m \u001b[38;5;66;03m# Each cell is a *single* input, regardless of how many lines it has\u001b[39;00m\n\u001b[32m   3385\u001b[39m \u001b[38;5;28mself\u001b[39m.execution_count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3435\u001b[39m, in \u001b[36mInteractiveShell._format_exception_for_storage\u001b[39m\u001b[34m(self, exception, filename, running_compiled_code)\u001b[39m\n\u001b[32m   3432\u001b[39m         stb = evalue._render_traceback_()\n\u001b[32m   3433\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3434\u001b[39m         \u001b[38;5;66;03m# Otherwise, use InteractiveTB to format the traceback.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3435\u001b[39m         stb = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mInteractiveTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3436\u001b[39m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   3437\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3438\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   3439\u001b[39m     \u001b[38;5;66;03m# In case formatting fails, fallback to Python's built-in formatting.\u001b[39;00m\n\u001b[32m   3440\u001b[39m     stb = traceback.format_exception(etype, evalue, tb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/IPython/core/ultratb.py:1182\u001b[39m, in \u001b[36mAutoFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1181\u001b[39m     \u001b[38;5;28mself\u001b[39m.tb = etb\n\u001b[32m-> \u001b[39m\u001b[32m1182\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/IPython/core/ultratb.py:1053\u001b[39m, in \u001b[36mFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1050\u001b[39m mode = \u001b[38;5;28mself\u001b[39m.mode\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose_modes:\n\u001b[32m   1052\u001b[39m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mDocs\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1057\u001b[39m     \u001b[38;5;66;03m# return DocTB\u001b[39;00m\n\u001b[32m   1058\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DocTB(\n\u001b[32m   1059\u001b[39m         theme_name=\u001b[38;5;28mself\u001b[39m._theme_name,\n\u001b[32m   1060\u001b[39m         call_pdb=\u001b[38;5;28mself\u001b[39m.call_pdb,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1068\u001b[39m         etype, evalue, etb, tb_offset, \u001b[32m1\u001b[39m\n\u001b[32m   1069\u001b[39m     )  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/IPython/core/ultratb.py:861\u001b[39m, in \u001b[36mVerboseTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m    852\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstructured_traceback\u001b[39m(\n\u001b[32m    853\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    854\u001b[39m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    858\u001b[39m     context: \u001b[38;5;28mint\u001b[39m = \u001b[32m5\u001b[39m,\n\u001b[32m    859\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    860\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m     formatted_exceptions: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m        \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    865\u001b[39m     termsize = \u001b[38;5;28mmin\u001b[39m(\u001b[32m75\u001b[39m, get_terminal_size()[\u001b[32m0\u001b[39m])\n\u001b[32m    866\u001b[39m     theme = theme_table[\u001b[38;5;28mself\u001b[39m._theme_name]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/IPython/core/ultratb.py:773\u001b[39m, in \u001b[36mVerboseTB.format_exception_as_a_whole\u001b[39m\u001b[34m(self, etype, evalue, etb, context, tb_offset)\u001b[39m\n\u001b[32m    763\u001b[39m         frames.append(\n\u001b[32m    764\u001b[39m             theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    765\u001b[39m                 [\n\u001b[32m   (...)\u001b[39m\u001b[32m    770\u001b[39m             )\n\u001b[32m    771\u001b[39m         )\n\u001b[32m    772\u001b[39m         skipped = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m     frames.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    774\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m skipped:\n\u001b[32m    775\u001b[39m     frames.append(\n\u001b[32m    776\u001b[39m         theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    777\u001b[39m             [\n\u001b[32m   (...)\u001b[39m\u001b[32m    782\u001b[39m         )\n\u001b[32m    783\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/IPython/core/ultratb.py:652\u001b[39m, in \u001b[36mVerboseTB.format_record\u001b[39m\u001b[34m(self, frame_info)\u001b[39m\n\u001b[32m    648\u001b[39m result += \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m call \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    649\u001b[39m result += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcall\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    650\u001b[39m result += theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    651\u001b[39m     _format_traceback_lines(\n\u001b[32m--> \u001b[39m\u001b[32m652\u001b[39m         \u001b[43mframe_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlines\u001b[49m,\n\u001b[32m    653\u001b[39m         theme_table[\u001b[38;5;28mself\u001b[39m._theme_name],\n\u001b[32m    654\u001b[39m         \u001b[38;5;28mself\u001b[39m.has_colors,\n\u001b[32m    655\u001b[39m         lvals_toks,\n\u001b[32m    656\u001b[39m     )\n\u001b[32m    657\u001b[39m )\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/IPython/core/tbtools.py:355\u001b[39m, in \u001b[36mFrameInfo.lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlines\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m NotOneValueFound:\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDummy\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/stack_data/utils.py:145\u001b[39m, in \u001b[36mcached_property.cached_property_wrapper\u001b[39m\u001b[34m(self, obj, _cls)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/stack_data/core.py:734\u001b[39m, in \u001b[36mFrameInfo.lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;129m@cached_property\u001b[39m\n\u001b[32m    719\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlines\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> List[Union[Line, LineGap, BlankLineRange]]:\n\u001b[32m    720\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    721\u001b[39m \u001b[33;03m    A list of lines to display, determined by options.\u001b[39;00m\n\u001b[32m    722\u001b[39m \u001b[33;03m    The objects yielded either have type Line, BlankLineRange\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    732\u001b[39m \u001b[33;03m    The Line objects are all within the ranges from .included_pieces.\u001b[39;00m\n\u001b[32m    733\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m     pieces = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mincluded_pieces\u001b[49m\n\u001b[32m    735\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pieces:\n\u001b[32m    736\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/stack_data/utils.py:145\u001b[39m, in \u001b[36mcached_property.cached_property_wrapper\u001b[39m\u001b[34m(self, obj, _cls)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/stack_data/core.py:677\u001b[39m, in \u001b[36mFrameInfo.included_pieces\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;129m@cached_property\u001b[39m\n\u001b[32m    667\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mincluded_pieces\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> List[\u001b[38;5;28mrange\u001b[39m]:\n\u001b[32m    668\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    669\u001b[39m \u001b[33;03m    The list of pieces (ranges of lines) to display for this frame.\u001b[39;00m\n\u001b[32m    670\u001b[39m \u001b[33;03m    Consists of .executing_piece, surrounding context pieces\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    675\u001b[39m \u001b[33;03m    Always a subset of .scope_pieces.\u001b[39;00m\n\u001b[32m    676\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m     scope_pieces = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscope_pieces\u001b[49m\n\u001b[32m    678\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.scope_pieces:\n\u001b[32m    679\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/stack_data/utils.py:145\u001b[39m, in \u001b[36mcached_property.cached_property_wrapper\u001b[39m\u001b[34m(self, obj, _cls)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/stack_data/core.py:617\u001b[39m, in \u001b[36mFrameInfo.scope_pieces\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    612\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.source.pieces\n\u001b[32m    614\u001b[39m scope_start, scope_end = \u001b[38;5;28mself\u001b[39m.source.line_range(\u001b[38;5;28mself\u001b[39m.scope)\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    616\u001b[39m     piece\n\u001b[32m--> \u001b[39m\u001b[32m617\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m piece \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpieces\u001b[49m\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m scope_start <= piece.start \u001b[38;5;129;01mand\u001b[39;00m piece.stop <= scope_end\n\u001b[32m    619\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/stack_data/utils.py:145\u001b[39m, in \u001b[36mcached_property.cached_property_wrapper\u001b[39m\u001b[34m(self, obj, _cls)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/stack_data/core.py:101\u001b[39m, in \u001b[36mSource.pieces\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tree:\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m     98\u001b[39m         \u001b[38;5;28mrange\u001b[39m(i, i + \u001b[32m1\u001b[39m)\n\u001b[32m     99\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.lines) + \u001b[32m1\u001b[39m)\n\u001b[32m    100\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_clean_pieces\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/stack_data/core.py:116\u001b[39m, in \u001b[36mSource._clean_pieces\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_clean_pieces\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[\u001b[38;5;28mrange\u001b[39m]:\n\u001b[32m    113\u001b[39m     pieces = \u001b[38;5;28mself\u001b[39m._raw_split_into_pieces(\u001b[38;5;28mself\u001b[39m.tree, \u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.lines) + \u001b[32m1\u001b[39m)\n\u001b[32m    114\u001b[39m     pieces = [\n\u001b[32m    115\u001b[39m         (start, end)\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m (start, end) \u001b[38;5;129;01min\u001b[39;00m pieces\n\u001b[32m    117\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m end > start\n\u001b[32m    118\u001b[39m     ]\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# Combine overlapping pieces, i.e. consecutive pieces where the end of the first\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# is greater than the start of the second.\u001b[39;00m\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m# This can happen when two statements are on the same line separated by a semicolon.\u001b[39;00m\n\u001b[32m    123\u001b[39m     new_pieces = pieces[:\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/stack_data/core.py:168\u001b[39m, in \u001b[36mSource._raw_split_into_pieces\u001b[39m\u001b[34m(self, stmt, start, end)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m rang, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(group_by_key_func(body, \u001b[38;5;28mself\u001b[39m.line_range).items()):\n\u001b[32m    167\u001b[39m     sub_stmt = group[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_end\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_split_into_pieces\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_stmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mrang\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_start\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_start\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/stack_data/core.py:168\u001b[39m, in \u001b[36mSource._raw_split_into_pieces\u001b[39m\u001b[34m(self, stmt, start, end)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m rang, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(group_by_key_func(body, \u001b[38;5;28mself\u001b[39m.line_range).items()):\n\u001b[32m    167\u001b[39m     sub_stmt = group[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_end\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_split_into_pieces\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_stmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mrang\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_start\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_start\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/stack_data/core.py:168\u001b[39m, in \u001b[36mSource._raw_split_into_pieces\u001b[39m\u001b[34m(self, stmt, start, end)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m rang, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(group_by_key_func(body, \u001b[38;5;28mself\u001b[39m.line_range).items()):\n\u001b[32m    167\u001b[39m     sub_stmt = group[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_end\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_split_into_pieces\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_stmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mrang\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_start\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_start\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/stack_data/core.py:164\u001b[39m, in \u001b[36mSource._raw_split_into_pieces\u001b[39m\u001b[34m(self, stmt, start, end)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_raw_split_into_pieces\u001b[39m(\n\u001b[32m    156\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    157\u001b[39m         stmt: ast.AST,\n\u001b[32m    158\u001b[39m         start: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m    159\u001b[39m         end: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m    160\u001b[39m ) -> Iterator[Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[32m    161\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, body \u001b[38;5;129;01min\u001b[39;00m ast.iter_fields(stmt):\n\u001b[32m    162\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    163\u001b[39m                 \u001b[38;5;28misinstance\u001b[39m(body, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m body \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m                 \u001b[38;5;28misinstance\u001b[39m(body[\u001b[32m0\u001b[39m], (ast.stmt, ast.ExceptHandler, \u001b[38;5;28mgetattr\u001b[39m(ast, \u001b[33m'\u001b[39m\u001b[33mmatch_case\u001b[39m\u001b[33m'\u001b[39m, ())))\n\u001b[32m    165\u001b[39m         ):\n\u001b[32m    166\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m rang, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(group_by_key_func(body, \u001b[38;5;28mself\u001b[39m.line_range).items()):\n\u001b[32m    167\u001b[39m                 sub_stmt = group[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "%%bash -s\n",
    "pip install pymupdf faiss-cpu sentence_transformers Pillow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f649cc03-91fe-4e0f-864a-4d089a2b0df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "125662a6-f715-4a00-b33b-1a447fa0da75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF pour l'extraction de texte et d'images\n",
    "import numpy as np\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# Import pour le NLP\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder,util\n",
    "from transformers import pipeline, BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "import torch\n",
    "import re\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ead7632-4b1d-42c6-9625-5bc6d4ca8a9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'huggingface_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m login\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#login(token=\"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\")  # Récupérez votre token ici : https://huggingface.co/settings/tokens\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#generator = pipeline(\"text-generation\", model=\"mistralai/Mistral-7B-v0.1\")\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'huggingface_hub'"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "#login(token=\"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\")  # Récupérez votre token ici : https://huggingface.co/settings/tokens\n",
    "\n",
    "#generator = pipeline(\"text-generation\", model=\"mistralai/Mistral-7B-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94788bb5-ac92-480b-bba2-f940d1c912c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script Global pour le système RAG appliqué aux rapports RSE.\n",
    "Comprend :\n",
    "    - Extraction de texte depuis un PDF\n",
    "    - Découpage en passages (chunking)\n",
    "    - Encodage avec MiniLM et indexation dans FAISS\n",
    "    - Recherche initiale et reranking (avec seuil de pertinence) via MiniLM Cross-Encoder\n",
    "    - Extraction et description d’images (image captioning) avec BLIP\n",
    "\n",
    "Avant de lancer ce script, installez les dépendances nécessaires :\n",
    "    pip install pymupdf sentence-transformers faiss-cpu transformers torch torchvision Pillow matplotlib pandas\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "############################################\n",
    "# 1. Extraction de texte depuis un PDF\n",
    "############################################\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extrait le texte d'un fichier PDF en concaténant le texte de chaque page.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def chunk_text(text):\n",
    "    \"\"\"\n",
    "    Découpe le texte en chunks (passages) en utilisant une taille fixe en nombre de mots,\n",
    "    avec un chevauchement pour préserver le contexte.\n",
    "    \"\"\"\n",
    "    chunk_size, overlap=300,30\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    step = chunk_size - overlap\n",
    "    for i in range(0, len(words), step):\n",
    "        chunk = words[i:i+chunk_size]\n",
    "        chunks.append(\" \".join(chunk))\n",
    "    return chunks\n",
    "\n",
    "def encode_passages(passages, model):\n",
    "    \"\"\"\n",
    "    Encode une liste de passages en vecteurs grâce au modèle d'embeddings.\n",
    "    \"\"\"\n",
    "    embeddings = model.encode(passages, show_progress_bar=True)\n",
    "    return np.array(embeddings, dtype=np.float32)\n",
    "\n",
    "def build_faiss_index(embeddings):\n",
    "    \"\"\"\n",
    "    Crée un index FAISS avec une recherche par distance L2.\n",
    "    \"\"\"\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(embeddings)\n",
    "    return index\n",
    "\n",
    "############################################\n",
    "# 4. Recherche initiale et Reranking avec seuil de pertinence\n",
    "############################################\n",
    "def retrieve_passages(query, passages, embedding_model, faiss_index, k=10):\n",
    "    \"\"\"\n",
    "    Recherche initiale : encode la requête, interroge FAISS pour récupérer les k passages les plus proches.\n",
    "    \"\"\"\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    distances, indices = faiss_index.search(np.array(query_embedding, dtype=np.float32), k)\n",
    "    retrieved = [passages[idx] for idx in indices[0] if idx < len(passages)]\n",
    "    return retrieved\n",
    "\n",
    "def rerank_passages(query, passages, reranker, threshold=0.4):\n",
    "    \"\"\"\n",
    "    Reranking des passages : utilise MiniLM Cross-Encoder pour calculer des scores de pertinence.\n",
    "    Seuls les passages avec un score supérieur au seuil sont reteÇnus.\n",
    "    \"\"\"\n",
    "    pairs = [(query, passage) for passage in passages]\n",
    "    scores = reranker.predict(pairs)\n",
    "    # Filtrage par seuil\n",
    "    filtered = [(passage, score) for passage, score in zip(passages, scores) if score > threshold]\n",
    "    # Tri décroissant par score\n",
    "    ranked = sorted(filtered, key=lambda x: x[1], reverse=True)\n",
    "    return ranked\n",
    "\n",
    "def generate_answer(query, ranked_passages, max_length=500):\n",
    "    \"\"\"\n",
    "    Génère une réponse en paragraphe à partir des passages rerankés.\n",
    "    \n",
    "    Args:\n",
    "        query (str): La question posée\n",
    "        ranked_passages (list): Liste de tuples (passage, score)\n",
    "        max_length (int): Longueur maximale de la réponse\n",
    "    \n",
    "    Returns:\n",
    "        str: Réponse formatée en paragraphe\n",
    "    \"\"\"\n",
    "     # 2. Créer le contexte pour le prompt\n",
    "    context = \"\\\\n\".join([f\"[Source {i+1}] {text}\"  for i, text in enumerate(ranked_passages)])  # Prendre les passages rerankes\n",
    "\n",
    "    # 3. Construire le prompt instruct\n",
    "    prompt = f\"\"\"<s>[INST] \n",
    "    En tant qu'expert en RSE, synthétisez une réponse précise en français en utilisant UNIQUEMENT \n",
    "    les sources fournies. Structurez la réponse en un paragraphe de 400 mots avec des points clés.\n",
    "\n",
    "    Question: {query}\n",
    "\n",
    "    Sources:\n",
    "    {context}\n",
    "    \n",
    "    Répondez dans un français clair et concis: [/INST]\"\"\"\n",
    "    \n",
    "    # 4. Génération avec Mistral (version ouverte alternative)\n",
    "\n",
    "    \n",
    "    response = generator(\n",
    "        prompt,\n",
    "        max_new_tokens=max_length,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    \n",
    "    return response[0]['generated_text'].split(\"[/INST]\")[-1].strip()\n",
    "def find_top_chunks_for_phrase(phrase, chunks, top_k=1, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Trouve les top_k chunks les plus similaires à une phrase pertinente.\n",
    "\n",
    "    Args:\n",
    "        phrase (str): La phrase de référence.\n",
    "        chunks (List[str]): Tous les chunks du document.\n",
    "        top_k (int): Nombre de passages à retourner.\n",
    "        threshold (float): Score de similarité minimale.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[int, float, str]]: (chunk_id, score, texte) triés par pertinence.\n",
    "    \"\"\"\n",
    "    # Encodage\n",
    "    phrase_embedding = embedding_model.encode(f\"query: {phrase}\", convert_to_tensor=True)\n",
    "    chunk_texts = [f\"passage: {chunk}\" for chunk in chunks]\n",
    "    chunk_embeddings = embedding_model.encode(chunk_texts, convert_to_tensor=True)\n",
    "\n",
    "    # Similarité cosinus\n",
    "    similarities = util.cos_sim(phrase_embedding, chunk_embeddings)[0]\n",
    "\n",
    "    # Tri décroissant\n",
    "    top_indices = torch.argsort(similarities, descending=True)\n",
    "\n",
    "    # Récupération des top chunks au-dessus du seuil\n",
    "    top_matches = []\n",
    "    for idx in top_indices[:top_k * 2]:  # on élargit au cas où certains soient sous le seuil\n",
    "        score = similarities[idx].item()\n",
    "        if score >= threshold:\n",
    "            top_matches.append((idx.item(), score, chunks[idx.item()]))\n",
    "        if len(top_matches) == top_k:\n",
    "            break\n",
    "\n",
    "    return top_matches\n",
    "    \n",
    "def calculate_mrr(\n",
    "    questions_data,\n",
    "    retrieved_passages_by_question,\n",
    "    threshold=0.85\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calcule le MRR en comparant uniquement le premier passage du ground truth \n",
    "    avec les chunks retrouvés (et non tous les chunks du corpus !).\n",
    "\n",
    "    Args:\n",
    "        questions_data (list): liste de questions + ground truth\n",
    "            [\n",
    "                {\n",
    "                    \"question\": \"...\",\n",
    "                    \"relevant_chunks\": [\"...\"]  # on prend le premier\n",
    "                },\n",
    "                ...\n",
    "            ]\n",
    "        retrieved_passages_by_question (dict): {question: [retrieved_chunks (texte)]}\n",
    "        threshold (float): seuil de similarité cosinus pour considérer un match\n",
    "\n",
    "    Returns:\n",
    "        float: MRR global\n",
    "    \"\"\"\n",
    "    reciprocal_ranks = []\n",
    "\n",
    "    for q_data in questions_data:\n",
    "        question = q_data[\"question\"]\n",
    "        ground_truth_chunk = q_data[\"relevant_chunks\"][0]  # on compare au 1er chunk GT\n",
    "\n",
    "        # Embedding du ground truth\n",
    "        gt_embedding = model.encode(f\"passage: {ground_truth_chunk}\", convert_to_tensor=True)\n",
    "\n",
    "        # Passages récupérés uniquement pour cette question\n",
    "        retrieved_passages = retrieved_passages_by_question.get(question, [])\n",
    "\n",
    "        found = False\n",
    "\n",
    "        for rank, passage in enumerate(retrieved_passages, start=1):\n",
    "            passage_embedding = model.encode(f\"passage: {passage}\", convert_to_tensor=True)\n",
    "            sim = util.cos_sim(gt_embedding, passage_embedding)[0][0].item()\n",
    "\n",
    "            if sim >= threshold:\n",
    "                reciprocal_ranks.append(1 / rank)\n",
    "                found = True\n",
    "                break  # stop at first match\n",
    "\n",
    "        if not found:\n",
    "            reciprocal_ranks.append(0.0)\n",
    "\n",
    "    return sum(reciprocal_ranks) / len(reciprocal_ranks) if reciprocal_ranks else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7468ec17-d943-4bbe-be6a-da07267a8f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file = os.listdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4da77f8-2f79-488f-b604-76281fedcd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What-contribution-do-banks-make-to-the-ecological-transition.pdf',\n",
       " '20240903-bnpparibas-csr-presentation-2024.pdf',\n",
       " '.ipynb_checkpoints',\n",
       " 'climate-change-and-the-banking-industry.pdf',\n",
       " 'as_101_climate_risk_banks_en.pdf',\n",
       " 'bnp_paribas_2023_climate_report.pdf',\n",
       " 'eib-group-2022-climate-bank-roadmap-progress-report.pdf',\n",
       " 'ssm.202011finalguideonclimate-relatedandenvironmentalrisks~58213f6564.fr.pdf']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f854fae9-36ed-4fd2-88e0-1934dedf1619",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pdf_file[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70b48980-a0b6-4a08-bd41-286eb7ca5797",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text=\"\"\n",
    "for doc in pdf_file:\n",
    "    pdf_path=\"data/\"+doc\n",
    "    full_text+=\" \"+ extract_text_from_pdf(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e68002-582a-4dd5-a10a-6311dd752aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aea320b-06d0-43a1-b3ad-fb1eaef9ac06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "752720"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1324b20-fd9a-45f2-833a-313ec93f8d87",
   "metadata": {},
   "source": [
    "### Initialisation du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a8094e4-be8e-4e36-ba60-8477d6abea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Extraction du texte et découpage en passages\n",
    "# passages = chunk_text(full_text)\n",
    "# print(f\"Nombre de passages extraits: {len(passages)}\")\n",
    "\n",
    "#  Chargement du embeddings e5\n",
    "embedding_model = SentenceTransformer(\"intfloat/multilingual-e5-large\")\n",
    "# passage_embeddings = encode_passages(passages, embedding_model)\n",
    "# faiss_index = build_faiss_index(passage_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6881e48b-522d-4a1e-930a-680deedb4b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba777cea-bd29-4def-aa58-a41429e6daa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de passages extraits: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:34<00:00, 34.63s/it]\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Passages récupérés (avant reranking) :\n",
      " - of the Group’s CSR policy, impacting the annual variable compensation applicable to the CEO and the  ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Définir une requête utilisateur\n",
    "    query = \"Quel est l’objectif de BNP Paribas pour les prêts durables d’ici 2025 ?\"#\"Quelles entreprises ont réduit leurs émissions de CO2 de manière significative ?\"\n",
    "\n",
    "    #  Recherche initiale via FAISS\n",
    "    retrieved_passages = retrieve_passages(query, passages, embedding_model, faiss_index, k=10)\n",
    "    print(\"\\nPassages récupérés (avant reranking) :\")\n",
    "    for p in retrieved_passages:\n",
    "        print(\" -\", p[:100], \"...\")\n",
    "    \n",
    "    # #  Reranking avec MiniLM Cross-Encoder\n",
    "    # reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "    # ranked_passages = rerank_passages(query, retrieved_passages, reranker, threshold=0.5)\n",
    "    \n",
    "    # print(\"\\nPassages après reranking et filtrage par seuil de pertinence :\")\n",
    "    # for i, (passage, score) in enumerate(ranked_passages, 1):\n",
    "    #     print(f\"{i}. (Score: {score:.2f}) {passage[:150]}...\")\n",
    "\n",
    "    #Generation    \n",
    "    # reponse = generate_answer(query, ranked_passages)\n",
    "    # print(\"Réponse générée:\\\\n\", reponse)\n",
    "\n",
    "        reponse = generate_answer(query, retrieved_passages)\n",
    "    print(\"Réponse générée:\\\\n\", reponse)\n",
    "\n",
    "    print(\"\\n Ta rag RAG exécuté avec succès.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0d93fe-514f-449f-b83f-613572eac7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bb7bf7-9cf1-4a9e-a386-0602c47d956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Le vrai ground truth (phrases pertinentes extraites manuellement)\n",
    "questions_data = [\n",
    "    {\n",
    "        \"question\": \"Quel est l’objectif de BNP Paribas pour les prêts durables d’ici 2025 ?\",\n",
    "        \"relevant_phrases\": [\n",
    "            \"BNP Paribas vise un montant de prêts durables de 150 milliards d’euros d’ici 2025 (contre 117 milliards en 2023).\",\n",
    "            \"Le groupe a réduit de 70% ses financements aux énergies fossiles depuis 2020.\",\n",
    "            \"BNP Paribas est classé #1 mondial en finance durable en 2023.\"\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "retrieved_ids = [passages.index(p) for p in retrieved_passages]\n",
    "\n",
    "# 3. Structure pour le calcul MRR\n",
    "retrieved_chunks_by_question = {\n",
    "    \"Quel est l’objectif de BNP Paribas pour les prêts durables d’ici 2025 ?\": retrieved_ids\n",
    "}\n",
    "\n",
    "# Calcul du MRR\n",
    "mrr = calculate_mrr(questions_data,all_chunks=passages, retrieved_chunks_by_question=retrieved_chunks_by_question, threshold=0.85\n",
    ")\n",
    "\n",
    "print(f\" MRR: {mrr:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a408c57-bdd5-4307-8808-4dac57dff9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c07bbbc-996c-4041-a16b-d42ab7330918",
   "metadata": {},
   "source": [
    "### Great Truth pour dautre test mrr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47bbe02-deb1-4f2f-aad2-ab8104bbc38a",
   "metadata": {},
   "source": [
    "##### On remplace query par la question et cesT OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef885c61-f57e-441c-90b9-346d8c3fc83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_data=[ {\n",
    "        \"question\": \"Quels sont les engagements climatiques de BNP Paribas pour 2050 ?\",\n",
    "        \"relevant_phrases\": [\n",
    "            \"BNP Paribas s’est engagée à atteindre la neutralité carbone d’ici 2050.\",\n",
    "            \"La banque aligne ses portefeuilles sur les scénarios de l’AIE.\"\n",
    "        ]\n",
    "    }\n",
    "               ]\n",
    "\n",
    "questions_data=[  {\n",
    "        \"question\": \"How does the EIB support adaptation to climate change in the European Union and beyond?\",\n",
    "        \"relevant_phrases\": [\n",
    "            \"In 2022 the EIB lent €1.8 billion for climate change adaptation, of which nearly 80% was in the European Union.\",\n",
    "            \"Project examples from 2022 include: EIB support to investments in the water and wastewater infrastructure of the city of Warsaw [...] and support to Andalusia’s rural development programme to improve water catchment, prevent soil erosion.\",\n",
    "       \"Beyond the European Union, EIB Global financed the Aqaba-Amman Water Desalination and Conveyance Project, the largest ever investment project for adapting the water sector to the impacts of climate change in Jordan.\"\n",
    "        ]\n",
    "    }\n",
    "               ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7099e05f-b6db-4769-a5f8-109d58a2e46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 13, done.\n",
      "Counting objects: 100% (13/13), done.\n",
      "Delta compression using up to 72 threads\n",
      "Compressing objects: 100% (13/13), done.\n",
      "Writing objects: 100% (13/13), 17.60 MiB | 11.54 MiB/s, done.\n",
      "Total 13 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\n",
      "remote: Resolving deltas: 100% (1/1), done.\u001b[K\n",
      "To https://github.com/cdieng0/projet-stattapp.git\n",
      " * [new branch]      main -> main\n",
      "branch 'main' set up to track 'origin/main'.\n"
     ]
    }
   ],
   "source": [
    "!git remote set-url origin https://cdieng0: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@github.com/cdieng0/projet-stattapp.git\n",
    "\n",
    "!git push -u origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f6acb3f-5ea2-4276-97a6-e3f43aaff9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!git config --global --add safe.directory /home/onyxia/work\n",
    "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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a19771e2-5713-4ce7-a2ac-a3bdc367c69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinitialized existing Git repository in /home/onyxia/work/projet-stattapp/.git/\n",
      "error: remote origin already exists.\n"
     ]
    }
   ],
   "source": [
    "!git init\n",
    "!git remote add origin https://github.com/cdieng0/onixiq.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c682939-eec8-44e7-bcb9-2ea046749218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 7859981] Nouveau commit propre avec le dossier images\n",
      " 1 file changed, 39 insertions(+), 13 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "!git add -A\n",
    "!git commit -m \"Nouveau commit propre avec le dossier images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c3ecc64-42d3-4254-a10a-254d775e8423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 8, done.\n",
      "Counting objects: 100% (8/8), done.\n",
      "Delta compression using up to 72 threads\n",
      "Compressing objects: 100% (6/6), done.\n",
      "Writing objects: 100% (6/6), 5.12 KiB | 2.56 MiB/s, done.\n",
      "Total 6 (delta 4), reused 0 (delta 0), pack-reused 0 (from 0)\n",
      "remote: Resolving deltas: 100% (4/4), completed with 2 local objects.\u001b[K\n",
      "remote: \u001b[1;31merror\u001b[m: GH013: Repository rule violations found for refs/heads/main.\u001b[K\n",
      "remote: \n",
      "remote: - GITHUB PUSH PROTECTION\u001b[K\n",
      "remote:   —————————————————————————————————————————\u001b[K\n",
      "remote:     Resolve the following violations before pushing again\u001b[K\n",
      "remote: \n",
      "remote:     - Push cannot contain secrets\u001b[K\n",
      "remote: \n",
      "remote:     \u001b[K\n",
      "remote:      (?) Learn how to resolve a blocked push\u001b[K\n",
      "remote:      https://docs.github.com/code-security/secret-scanning/working-with-secret-scanning-and-push-protection/working-with-push-protection-from-the-command-line#resolving-a-blocked-push\u001b[K\n",
      "remote:     \u001b[K\n",
      "remote:     \u001b[K\n",
      "remote:       —— GitHub Personal Access Token ——————————————————————\u001b[K\n",
      "remote:        locations:\u001b[K\n",
      "remote:          - commit: 7859981ea92c9d9fe4522e4dea5c15eaa6af9b6e\u001b[K\n",
      "remote:            path: rag?rse.ipynb:819\u001b[K\n",
      "remote:          - commit: d3ab131fab115786c6340fa5e546df5b8b8d2cd9\u001b[K\n",
      "remote:            path: rag?rse.ipynb:819\u001b[K\n",
      "remote:          - commit: 7859981ea92c9d9fe4522e4dea5c15eaa6af9b6e\u001b[K\n",
      "remote:            path: rag?rse.ipynb:833\u001b[K\n",
      "remote:          - commit: d3ab131fab115786c6340fa5e546df5b8b8d2cd9\u001b[K\n",
      "remote:            path: rag?rse.ipynb:833\u001b[K\n",
      "remote:     \u001b[K\n",
      "remote:        (?) To push, remove secret from commit(s) or follow this URL to allow the secret.\u001b[K\n",
      "remote:        https://github.com/cdieng0/projet-stattapp/security/secret-scanning/unblock-secret/2vk2jOgQCZ6qNPAUq3L5Jllces5\u001b[K\n",
      "remote:     \u001b[K\n",
      "remote: \n",
      "remote: \n",
      "To https://github.com/cdieng0/projet-stattapp.git\n",
      " \u001b[31m! [remote rejected]\u001b[m main -> main (push declined due to repository rule violations)\n",
      "\u001b[31merror: failed to push some refs to 'https://github.com/cdieng0/projet-stattapp.git'\n",
      "\u001b[m"
     ]
    }
   ],
   "source": [
    "!git push -u origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7626603-f641-413c-9c00-8c4a3bfc0c65",
   "metadata": {},
   "source": [
    "### Extraction image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f48b7318-7e32-45cc-b5ca-fd3879deea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_images_from_pdf(pdf_path, output_folder=\"images_extraits\"):\n",
    "    \"\"\"\n",
    "    Extrait toutes les images d'un fichier PDF et les enregistre dans un dossier \"images_extraits\".\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Chemin vers le fichier PDF.\n",
    "        output_folder (str): Dossier de sortie pour enregistrer les images.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: Liste des chemins des images extraites.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    image_paths = []\n",
    "    image_count = 0\n",
    "\n",
    "    for page_number in range(len(doc)):\n",
    "        page = doc[page_number]\n",
    "        images = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(images):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image_ext = base_image[\"ext\"]\n",
    "            pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "            image_filename = f\"{output_folder}/{pdf_name}_page{page_number + 1}_img{img_index + 1}.{image_ext}\"\n",
    "            with open(image_filename, \"wb\") as f:\n",
    "                f.write(image_bytes)\n",
    "            \n",
    "            image_paths.append(image_filename)\n",
    "            image_count += 1\n",
    "\n",
    "    print(f\"{image_count} image(s) extraite(s) dans le dossier '{output_folder}'.\")\n",
    "    return image_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a8a35c-554f-4fe7-a0e5-fc876d39e04f",
   "metadata": {},
   "source": [
    "### image pertinente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64c72ddd-60ac-447d-a948-2137a96fc13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sur le fichier as 101 du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c972a7-57e9-4812-8ee5-c0b09c98d5b8",
   "metadata": {},
   "source": [
    "#### Transcription img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "431d7396-a2b2-4537-83e2-d3fe40d66f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "806595d5-2a6f-48e2-901e-cbb6926ac757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_caption(image_path):\n",
    "    raw_image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(raw_image, return_tensors=\"pt\")\n",
    "    out = model.generate(**inputs, max_new_tokens=200)\n",
    "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "    return caption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c84065-443f-4d24-b85b-6ba0811e6414",
   "metadata": {},
   "source": [
    "#### stockage dans un fichier csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b877f29-0209-45bc-b679-c03e25e8249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caption_dataset(img_paths, output_csv, img_folder=\"images\"):\n",
    "    data = []\n",
    "\n",
    "    for path in img_paths:\n",
    "        caption = generate_image_caption(\"images/\"+path)\n",
    "        data.append({\n",
    "            \"image_filename\":os.path.basename(path),\n",
    "            \"caption\": caption,\n",
    "           # \"image_embedding\" :encode_passages(caption, embedding_model) \n",
    "        })\n",
    "        print(f\" {os.path.basename(path)} → {img_paths.index(path)} → {caption}\")\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
    "    print(f\"\\n CSV généré avec {len(df)} lignes :::: {output_csv}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1799483-413c-4f38-b4fa-6eaa65fa7ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths=os.listdir(\"images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f587713-9000-44f8-b8bd-115595f0ad35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# On garde uniquement ceux qui se terminent par .jpeg ou .png\n",
    "img_paths = [f for f in img_paths if f.endswith(('.jpeg', '.png'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8927028a-7a85-4b15-895e-55e344ada855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17a845b4-5178-4c21-8296-22ae2bec9745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_paths.index(\"20240903-bnpparibas-csr-presentation-2024_page5_img1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93633cad-2bf9-43e0-bfb2-7c7fbcd55854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20240903-bnpparibas-csr-presentation-2024_page5_img1.png → 0 → a black and white image of a black and white image of a black and white image of a black and\n"
     ]
    }
   ],
   "source": [
    "caption_dataset(img_paths,\"caption_image.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c13ead-d403-4a01-b338-8ad22564435a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9e6697a-597f-47d6-9823-be20151a26c6",
   "metadata": {},
   "source": [
    "#### fusionner des fichier csv en un seul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcbebffc-b157-4b1b-8dd1-959dea616af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusionner_csv(dossier_path, separateur=',', encodage='utf-8'):\n",
    "    \"\"\"\n",
    "    Fusionne tous les fichiers CSV d’un dossier donné en un seul fichier nommé 'fusion.csv'.\n",
    "\n",
    "    Paramètres :\n",
    "    - dossier_path : chemin vers le dossier contenant les fichiers CSV\n",
    "    - separateur : séparateur utilisé dans les fichiers CSV (par défaut = ',')\n",
    "    - encodage : encodage des fichiers (par défaut = 'utf-8')\n",
    "    \"\"\"\n",
    "    fichiers = [f for f in os.listdir(dossier_path) if f.endswith('.csv')]\n",
    "    dataframes = []\n",
    "\n",
    "    for fichier in fichiers:\n",
    "        chemin_complet = os.path.join(dossier_path, fichier)\n",
    "        df = pd.read_csv(chemin_complet, sep=separateur, encoding=encodage)\n",
    "        dataframes.append(df)\n",
    "\n",
    "    fusion = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Écriture du résultat dans un fichier CSV nommé 'fusion.csv'\n",
    "    chemin_sortie = os.path.join(dossier_path, 'fusion_image.csv')\n",
    "    fusion.to_csv(chemin_sortie, index=False, sep=separateur, encoding=encodage)\n",
    "\n",
    "    print(f\" Fusion terminée : {chemin_sortie}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf4e682-4a77-4538-9507-592ed1a3ce0a",
   "metadata": {},
   "source": [
    "### ajout colonne finale imgembeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a940c27-82f4-49e1-915f-d59fccc320a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data= pd.read_csv(\"FICHIERCSSV/fusion_image.csv\")\n",
    "data[\"image_embedding\"] = data[\"caption\"].apply(lambda x: embedding_model.encode(x).tolist())\n",
    "data.to_csv(\"FICHIERCSSV/final_fusion_image.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c0874c-2152-4032-8948-b8cd1f503acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def illustration_image(answer):\n",
    "   \n",
    "    answer_embedding = embedding_model.encode(answer, convert_to_tensor=True)\n",
    "    \n",
    "    # Calcul de similarité\n",
    "    similarities = util.cos_sim(answer_embedding, data[\"image_embedding\"])[0]\n",
    "    top_image_idx = torch.argmax(similarities).item()\n",
    "    top_image = data[\"image_embedding\"].iloc[top_image_idx]\n",
    "    \n",
    "    if similarities[top_image_idx] > 0.7:  # Seuil à ajuster\n",
    "        Image.open(data[\"image_name\"].iloc[top_image_idx]).show()\n",
    "        print(f\"{answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
