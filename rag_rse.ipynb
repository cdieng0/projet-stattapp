{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bdc9ac09-d735-4a63-8565-3809696515d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdc9ac09-d735-4a63-8565-3809696515d0",
        "outputId": "83649234-018f-49d5-8c22-5953a7583918"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.5\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.51.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (0.30.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymupdf\n",
        "!pip install faiss-cpu\n",
        "!pip install sentence_transformers\n",
        "!pip install Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f649cc03-91fe-4e0f-864a-4d089a2b0df2",
      "metadata": {
        "id": "f649cc03-91fe-4e0f-864a-4d089a2b0df2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "125662a6-f715-4a00-b33b-1a447fa0da75",
      "metadata": {
        "id": "125662a6-f715-4a00-b33b-1a447fa0da75"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import fitz  # PyMuPDF pour l'extraction de texte et d'images\n",
        "import numpy as np\n",
        "import faiss\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from nltk.tokenize import sent_tokenize\n",
        "# Import pour le NLP\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder,util\n",
        "from transformers import pipeline, BlipProcessor, BlipForConditionalGeneration\n",
        "from PIL import Image\n",
        "import torch\n",
        "import re\n",
        "from huggingface_hub import login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2ead7632-4b1d-42c6-9625-5bc6d4ca8a9f",
      "metadata": {
        "id": "2ead7632-4b1d-42c6-9625-5bc6d4ca8a9f"
      },
      "outputs": [],
      "source": [
        "# from huggingface_hub import login\n",
        "\n",
        "# login(token=\"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\")  # Récupérez votre token ici : https://huggingface.co/settings/tokens\n",
        "\n",
        "# generator = pipeline(\"text-generation\", model=\"mistralai/Mistral-7B-v0.1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "94788bb5-ac92-480b-bba2-f940d1c912c9",
      "metadata": {
        "id": "94788bb5-ac92-480b-bba2-f940d1c912c9"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"\n",
        "    Extrait le texte brut d’un fichier PDF.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Chemin vers le fichier PDF.\n",
        "\n",
        "    Returns:\n",
        "        str: Texte complet extrait du PDF, concaténé page par page avec des sauts de ligne.\n",
        "    \"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text() + \"\\n\"\n",
        "    return text\n",
        "\n",
        "\n",
        "def chunk_text(text):\n",
        "    \"\"\"\n",
        "    Découpe le texte en morceaux (chunks) de taille fixe avec recouvrement (overlap).\n",
        "\n",
        "    Args:\n",
        "        text (str): Texte complet à découper.\n",
        "\n",
        "    Returns:\n",
        "        list: Liste de chaînes de caractères, chaque chunk contenant environ 300 mots\n",
        "              avec 30 mots de chevauchement pour préserver le contexte.\n",
        "    \"\"\"\n",
        "    chunk_size, overlap = 300, 30\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    step = chunk_size - overlap\n",
        "    for i in range(0, len(words), step):\n",
        "        chunk = words[i:i+chunk_size]\n",
        "        chunks.append(\" \".join(chunk))\n",
        "    return chunks\n",
        "\n",
        "\n",
        "def encode_passages(passages, model):\n",
        "    \"\"\"\n",
        "    Encode chaque passage textuel en vecteur d’embedding avec un modèle de type SentenceTransformer.\n",
        "\n",
        "    Args:\n",
        "        passages (list): Liste de chaînes de caractères à encoder.\n",
        "        model (SentenceTransformer): Modèle d'embedding, par exemple E5 ou MiniLM.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Matrice d’embeddings de type float32 (shape: [n_passages, embedding_dim]).\n",
        "    \"\"\"\n",
        "    embeddings = model.encode(passages, show_progress_bar=True)\n",
        "    return np.array(embeddings, dtype=np.float32)\n",
        "\n",
        "\n",
        "def build_faiss_index(embeddings):\n",
        "    \"\"\"\n",
        "    Construit un index FAISS à partir des embeddings (utilise la distance L2).\n",
        "\n",
        "    Args:\n",
        "        embeddings (np.ndarray): Matrice des embeddings à indexer (shape: [n, d]).\n",
        "\n",
        "    Returns:\n",
        "        faiss.IndexFlatL2: Index FAISS entraîné et prêt pour les requêtes.\n",
        "    \"\"\"\n",
        "    dimension = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dimension)\n",
        "    index.add(embeddings)\n",
        "    return index\n",
        "\n",
        "\n",
        "def retrieve_passages(query, passages, embedding_model, faiss_index, k=10):\n",
        "    \"\"\"\n",
        "    Recherche les k passages les plus pertinents pour une requête donnée à l'aide de FAISS.\n",
        "\n",
        "    Args:\n",
        "        query (str): Question ou phrase à rechercher.\n",
        "        passages (list): Liste des passages (chunks) d’origine.\n",
        "        embedding_model (SentenceTransformer): Modèle d’embedding utilisé pour encoder la requête.\n",
        "        faiss_index (faiss.IndexFlatL2): Index FAISS contenant les embeddings des passages.\n",
        "        k (int): Nombre de résultats à retourner.\n",
        "\n",
        "    Returns:\n",
        "        list: Liste des k passages les plus proches (par similarité).\n",
        "    \"\"\"\n",
        "    query_embedding = embedding_model.encode([query])\n",
        "    distances, indices = faiss_index.search(np.array(query_embedding, dtype=np.float32), k)\n",
        "    retrieved = [passages[idx] for idx in indices[0] if idx < len(passages)]\n",
        "    return retrieved\n",
        "\n",
        "\n",
        "def rerank_passages(query, passages, reranker, threshold=0.4):\n",
        "    \"\"\"\n",
        "    Recalcule la pertinence des passages récupérés avec un modèle Cross-Encoder type MiniLM,\n",
        "    puis filtre et trie les passages les plus pertinents.\n",
        "\n",
        "    Args:\n",
        "        query (str): Question initiale de l’utilisateur.\n",
        "        passages (list): Passages récupérés initialement via FAISS.\n",
        "        reranker (CrossEncoder): Modèle Cross-Encoder (type ms-marco) pour scoring binaire.\n",
        "        threshold (float): Seuil minimal pour conserver un passage.\n",
        "\n",
        "    Returns:\n",
        "        list of tuples: Liste de (passage, score) triés par score décroissant.\n",
        "    \"\"\"\n",
        "    pairs = [(query, passage) for passage in passages]\n",
        "    scores = reranker.predict(pairs)\n",
        "    filtered = [(passage, score) for passage, score in zip(passages, scores) if score > threshold]\n",
        "    ranked = sorted(filtered, key=lambda x: x[1], reverse=True)\n",
        "    return ranked\n",
        "\n",
        "\n",
        "def generate_answer(query, ranked_passages, max_length=500):\n",
        "    \"\"\"\n",
        "    Génère une réponse en paragraphe à partir des passages rerankés.\n",
        "\n",
        "    Args:\n",
        "        query (str): La question posée\n",
        "        ranked_passages (list): Liste de tuples (passage, score)\n",
        "        max_length (int): Longueur maximale de la réponse\n",
        "\n",
        "    Returns:\n",
        "        str: Réponse formatée en paragraphe\n",
        "    \"\"\"\n",
        "     # 2. Créer le contexte pour le prompt\n",
        "    context = \"\\\\n\".join([f\"[Source {i+1}] {text}\"  for i, text in enumerate(ranked_passages)])  # Prendre les passages rerankes\n",
        "\n",
        "    # 3. Construire le prompt instruct\n",
        "    prompt = f\"\"\"<s>[INST]\n",
        "    En tant qu'expert en RSE, synthétisez une réponse précise en français en utilisant UNIQUEMENT\n",
        "    les sources fournies. Structurez la réponse en un paragraphe de 400 mots avec des points clés.\n",
        "\n",
        "    Question: {query}\n",
        "\n",
        "    Sources:\n",
        "    {context}\n",
        "\n",
        "    Répondez dans un français clair et concis: [/INST]\"\"\"\n",
        "\n",
        "    # 4. Génération avec Mistral (version ouverte alternative)\n",
        "\n",
        "\n",
        "    response = generator(\n",
        "        prompt,\n",
        "        max_new_tokens=max_length,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        num_return_sequences=1\n",
        "    )\n",
        "\n",
        "    return response[0]['generated_text'].split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "\n",
        "def find_top_chunks_for_phrase(phrase, chunks, top_k=4, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Trouve les top_k chunks les plus similaires à une phrase pertinente.\n",
        "\n",
        "    Args:\n",
        "        phrase (str): La phrase de référence.\n",
        "        chunks (List[str]): Tous les chunks du document.\n",
        "        top_k (int): Nombre de passages à retourner.\n",
        "        threshold (float): Score de similarité minimale.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[int, float, str]]: (chunk_id, score, texte) triés par pertinence.\n",
        "    \"\"\"\n",
        "    # Encodage\n",
        "    phrase_embedding = embedding_model.encode(f\"query: {phrase}\", convert_to_tensor=True)\n",
        "    chunk_texts = [f\"passage: {chunk}\" for chunk in chunks]\n",
        "    chunk_embeddings = embedding_model.encode(chunk_texts, convert_to_tensor=True)\n",
        "\n",
        "    # Similarité cosinus\n",
        "    similarities = util.cos_sim(phrase_embedding, chunk_embeddings)[0]\n",
        "\n",
        "    # Tri décroissant\n",
        "    top_indices = torch.argsort(similarities, descending=True)\n",
        "\n",
        "    # Récupération des top chunks au-dessus du seuil\n",
        "    top_matches = []\n",
        "    for idx in top_indices[:top_k * 2]:  # on élargit au cas où certains soient sous le seuil\n",
        "        score = similarities[idx].item()\n",
        "        if score >= threshold:\n",
        "            top_matches.append((idx.item(), score, chunks[idx.item()]))\n",
        "        if len(top_matches) == top_k:\n",
        "            break\n",
        "\n",
        "    return top_matches\n",
        "\n",
        "def calculate_mrr(questions_data, retrieved_passages_by_question, threshold=0.85):\n",
        "    \"\"\"\n",
        "    Calcule le MRR en comparant uniquement le premier passage du ground truth\n",
        "    avec les chunks retrouvés (et non tous les chunks du corpus !).\n",
        "\n",
        "    Args:\n",
        "        questions_data (list): liste de questions + ground truth\n",
        "            [\n",
        "                {\n",
        "                    \"question\": \"...\",\n",
        "                    \"relevant_chunks\": [\"...\"]  # on prend le premier\n",
        "                },\n",
        "                ...\n",
        "            ]\n",
        "        retrieved_passages_by_question (dict): {question: [retrieved_chunks (texte)]}\n",
        "        threshold (float): seuil de similarité cosinus pour considérer un match\n",
        "\n",
        "    Returns:\n",
        "        float: MRR global\n",
        "    \"\"\"\n",
        "    reciprocal_ranks = []\n",
        "\n",
        "    for q_data in questions_data:\n",
        "        question = q_data[\"question\"]\n",
        "        ground_truth_chunk = q_data[\"relevant_chunks\"][0]  # on compare au 1er chunk GT\n",
        "\n",
        "        # Embedding du ground truth\n",
        "        gt_embedding = model.encode(f\"passage: {ground_truth_chunk}\", convert_to_tensor=True)\n",
        "\n",
        "        # Passages récupérés uniquement pour cette question\n",
        "        retrieved_passages = retrieved_passages_by_question.get(question, [])\n",
        "\n",
        "        found = False\n",
        "\n",
        "        for rank, passage in enumerate(retrieved_passages, start=1):\n",
        "            passage_embedding = model.encode(f\"passage: {passage}\", convert_to_tensor=True)\n",
        "            sim = util.cos_sim(gt_embedding, passage_embedding)[0][0].item()\n",
        "\n",
        "            if sim >= threshold:\n",
        "                reciprocal_ranks.append(1 / rank)\n",
        "                found = True\n",
        "                break  # stop at first match\n",
        "\n",
        "        if not found:\n",
        "            reciprocal_ranks.append(0.0)\n",
        "\n",
        "    return sum(reciprocal_ranks) / len(reciprocal_ranks) if reciprocal_ranks else 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7468ec17-d943-4bbe-be6a-da07267a8f4e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "7468ec17-d943-4bbe-be6a-da07267a8f4e",
        "outputId": "fb5eefa3-8d2f-425c-f17b-ea03158018bf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b8f6caf1b672>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpdf_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ],
      "source": [
        "pdf_file = os.listdir(\"data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4da77f8-2f79-488f-b604-76281fedcd02",
      "metadata": {
        "id": "d4da77f8-2f79-488f-b604-76281fedcd02"
      },
      "outputs": [],
      "source": [
        "pdf_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70b48980-a0b6-4a08-bd41-286eb7ca5797",
      "metadata": {
        "id": "70b48980-a0b6-4a08-bd41-286eb7ca5797"
      },
      "outputs": [],
      "source": [
        "full_text=\"\"\n",
        "for doc in pdf_file:\n",
        "    pdf_path=\"data/\"+doc\n",
        "    full_text+=\" \"+ extract_text_from_pdf(pdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92e68002-582a-4dd5-a10a-6311dd752aa5",
      "metadata": {
        "id": "92e68002-582a-4dd5-a10a-6311dd752aa5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aea320b-06d0-43a1-b3ad-fb1eaef9ac06",
      "metadata": {
        "id": "9aea320b-06d0-43a1-b3ad-fb1eaef9ac06",
        "outputId": "b4d71b54-6c56-440e-a098-fe94292b984d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "752720"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(full_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1324b20-fd9a-45f2-833a-313ec93f8d87",
      "metadata": {
        "id": "f1324b20-fd9a-45f2-833a-313ec93f8d87"
      },
      "source": [
        "### Initialisation du model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2a8094e4-be8e-4e36-ba60-8477d6abea56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "2a8094e4-be8e-4e36-ba60-8477d6abea56",
        "outputId": "4019864b-0298-4fc4-862a-cc5c0c790cc7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'full_text' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-424329e56925>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#  Extraction du texte et découpage en passages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpassages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Nombre de passages extraits: {len(passages)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#  Chargement du embeddings e5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'full_text' is not defined"
          ]
        }
      ],
      "source": [
        " #  Extraction du texte et découpage en passages\n",
        " passages = chunk_text(full_text)\n",
        " print(f\"Nombre de passages extraits: {len(passages)}\")\n",
        "\n",
        "#  Chargement du embeddings e5\n",
        "embedding_model = SentenceTransformer(\"intfloat/multilingual-e5-large\")\n",
        " passage_embeddings = encode_passages(passages, embedding_model)\n",
        " faiss_index = build_faiss_index(passage_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6881e48b-522d-4a1e-930a-680deedb4b8a",
      "metadata": {
        "id": "6881e48b-522d-4a1e-930a-680deedb4b8a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba777cea-bd29-4def-aa58-a41429e6daa3",
      "metadata": {
        "id": "ba777cea-bd29-4def-aa58-a41429e6daa3",
        "outputId": "28431c0a-c762-4b74-9c7d-eb58a1828b08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre de passages extraits: 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 1/1 [00:34<00:00, 34.63s/it]\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Passages récupérés (avant reranking) :\n",
            " - of the Group’s CSR policy, impacting the annual variable compensation applicable to the CEO and the  ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Définir une requête utilisateur\n",
        "    query = \"Quel est l’objectif de BNP Paribas pour les prêts durables d’ici 2025 ?\"#\"Quelles entreprises ont réduit leurs émissions de CO2 de manière significative ?\"\n",
        "\n",
        "    #  Recherche initiale via FAISS\n",
        "    retrieved_passages = retrieve_passages(query, passages, embedding_model, faiss_index, k=10)\n",
        "    print(\"\\nPassages récupérés (avant reranking) :\")\n",
        "    for p in retrieved_passages:\n",
        "        print(\" -\", p[:100], \"...\")\n",
        "\n",
        "    # #  Reranking avec MiniLM Cross-Encoder\n",
        "    # reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
        "    # ranked_passages = rerank_passages(query, retrieved_passages, reranker, threshold=0.5)\n",
        "\n",
        "    # print(\"\\nPassages après reranking et filtrage par seuil de pertinence :\")\n",
        "    # for i, (passage, score) in enumerate(ranked_passages, 1):\n",
        "    #     print(f\"{i}. (Score: {score:.2f}) {passage[:150]}...\")\n",
        "\n",
        "    #Generation\n",
        "    # reponse = generate_answer(query, ranked_passages)\n",
        "    # print(\"Réponse générée:\\\\n\", reponse)\n",
        "\n",
        "        reponse = generate_answer(query, retrieved_passages)\n",
        "    print(\"Réponse générée:\\\\n\", reponse)\n",
        "\n",
        "    print(\"\\n Ta rag RAG exécuté avec succès.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb0d93fe-514f-449f-b83f-613572eac7b2",
      "metadata": {
        "id": "fb0d93fe-514f-449f-b83f-613572eac7b2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33bb7bf7-9cf1-4a9e-a386-0602c47d956e",
      "metadata": {
        "id": "33bb7bf7-9cf1-4a9e-a386-0602c47d956e"
      },
      "outputs": [],
      "source": [
        "#  Le vrai ground truth (phrases pertinentes extraites manuellement)\n",
        "questions_data = [\n",
        "    {\n",
        "        \"question\": \"Quel est l’objectif de BNP Paribas pour les prêts durables d’ici 2025 ?\",\n",
        "        \"relevant_phrases\": [\n",
        "            \"BNP Paribas vise un montant de prêts durables de 150 milliards d’euros d’ici 2025 (contre 117 milliards en 2023).\",\n",
        "            \"Le groupe a réduit de 70% ses financements aux énergies fossiles depuis 2020.\",\n",
        "            \"BNP Paribas est classé #1 mondial en finance durable en 2023.\"\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "retrieved_ids = [passages.index(p) for p in retrieved_passages]\n",
        "\n",
        "# 3. Structure pour le calcul MRR\n",
        "retrieved_chunks_by_question = {\n",
        "    \"Quel est l’objectif de BNP Paribas pour les prêts durables d’ici 2025 ?\": retrieved_ids\n",
        "}\n",
        "\n",
        "# Calcul du MRR\n",
        "mrr = calculate_mrr(questions_data,all_chunks=passages, retrieved_chunks_by_question=retrieved_chunks_by_question, threshold=0.85\n",
        ")\n",
        "\n",
        "print(f\" MRR: {mrr:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a408c57-bdd5-4307-8808-4dac57dff9f1",
      "metadata": {
        "id": "5a408c57-bdd5-4307-8808-4dac57dff9f1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2c07bbbc-996c-4041-a16b-d42ab7330918",
      "metadata": {
        "id": "2c07bbbc-996c-4041-a16b-d42ab7330918"
      },
      "source": [
        "### Great Truth pour dautre test mrr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f47bbe02-deb1-4f2f-aad2-ab8104bbc38a",
      "metadata": {
        "id": "f47bbe02-deb1-4f2f-aad2-ab8104bbc38a"
      },
      "source": [
        "##### On remplace query par la question et cesT OK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef885c61-f57e-441c-90b9-346d8c3fc83b",
      "metadata": {
        "id": "ef885c61-f57e-441c-90b9-346d8c3fc83b"
      },
      "outputs": [],
      "source": [
        "questions_data=[ {\n",
        "        \"question\": \"Quels sont les engagements climatiques de BNP Paribas pour 2050 ?\",\n",
        "        \"relevant_phrases\": [\n",
        "            \"BNP Paribas s’est engagée à atteindre la neutralité carbone d’ici 2050.\",\n",
        "            \"La banque aligne ses portefeuilles sur les scénarios de l’AIE.\"\n",
        "        ]\n",
        "    }\n",
        "               ]\n",
        "\n",
        "questions_data=[  {\n",
        "        \"question\": \"How does the EIB support adaptation to climate change in the European Union and beyond?\",\n",
        "        \"relevant_phrases\": [\n",
        "            \"In 2022 the EIB lent €1.8 billion for climate change adaptation, of which nearly 80% was in the European Union.\",\n",
        "            \"Project examples from 2022 include: EIB support to investments in the water and wastewater infrastructure of the city of Warsaw [...] and support to Andalusia’s rural development programme to improve water catchment, prevent soil erosion.\",\n",
        "       \"Beyond the European Union, EIB Global financed the Aqaba-Amman Water Desalination and Conveyance Project, the largest ever investment project for adapting the water sector to the impacts of climate change in Jordan.\"\n",
        "        ]\n",
        "    }\n",
        "               ]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7626603-f641-413c-9c00-8c4a3bfc0c65",
      "metadata": {
        "id": "d7626603-f641-413c-9c00-8c4a3bfc0c65"
      },
      "source": [
        "### Extraction image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f48b7318-7e32-45cc-b5ca-fd3879deea24",
      "metadata": {
        "id": "f48b7318-7e32-45cc-b5ca-fd3879deea24"
      },
      "outputs": [],
      "source": [
        "\n",
        "def extract_images_from_pdf(pdf_path, output_folder=\"images_extraits\"):\n",
        "    \"\"\"\n",
        "    Extrait toutes les images d'un fichier PDF et les enregistre dans un dossier \"images_extraits\".\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Chemin vers le fichier PDF.\n",
        "        output_folder (str): Dossier de sortie pour enregistrer les images.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: Liste des chemins des images extraites.\n",
        "    \"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    image_paths = []\n",
        "    image_count = 0\n",
        "\n",
        "    for page_number in range(len(doc)):\n",
        "        page = doc[page_number]\n",
        "        images = page.get_images(full=True)\n",
        "\n",
        "        for img_index, img in enumerate(images):\n",
        "            xref = img[0]\n",
        "            base_image = doc.extract_image(xref)\n",
        "            image_bytes = base_image[\"image\"]\n",
        "            image_ext = base_image[\"ext\"]\n",
        "            pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
        "            image_filename = f\"{output_folder}/{pdf_name}_page{page_number + 1}_img{img_index + 1}.{image_ext}\"\n",
        "            with open(image_filename, \"wb\") as f:\n",
        "                f.write(image_bytes)\n",
        "\n",
        "            image_paths.append(image_filename)\n",
        "            image_count += 1\n",
        "\n",
        "    print(f\"{image_count} image(s) extraite(s) dans le dossier '{output_folder}'.\")\n",
        "    return image_paths\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0a8a35c-554f-4fe7-a0e5-fc876d39e04f",
      "metadata": {
        "id": "d0a8a35c-554f-4fe7-a0e5-fc876d39e04f"
      },
      "source": [
        "### image pertinente"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8c972a7-57e9-4812-8ee5-c0b09c98d5b8",
      "metadata": {
        "id": "c8c972a7-57e9-4812-8ee5-c0b09c98d5b8"
      },
      "source": [
        "#### Transcription img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "431d7396-a2b2-4537-83e2-d3fe40d66f50",
      "metadata": {
        "id": "431d7396-a2b2-4537-83e2-d3fe40d66f50",
        "outputId": "bc851e96-3eeb-4ed5-847b-c6cde5ef2a06"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        }
      ],
      "source": [
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "806595d5-2a6f-48e2-901e-cbb6926ac757",
      "metadata": {
        "id": "806595d5-2a6f-48e2-901e-cbb6926ac757"
      },
      "outputs": [],
      "source": [
        "def generate_image_caption(image_path):\n",
        "    \"\"\"\n",
        "    Génère une description textuelle (caption) pour une image donnée en utilisant un modèle de type BLIP.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Chemin vers l'image à analyser (doit être un fichier image lisible par PIL).\n",
        "\n",
        "    Returns:\n",
        "        str: Légende générée automatiquement décrivant le contenu visuel de l'image.\n",
        "\n",
        "    \"\"\"\n",
        "    raw_image = Image.open(image_path).convert(\"RGB\")\n",
        "    inputs = processor(raw_image, return_tensors=\"pt\")\n",
        "    out = model.generate(**inputs, max_new_tokens=200)\n",
        "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "    return caption\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75c84065-443f-4d24-b85b-6ba0811e6414",
      "metadata": {
        "id": "75c84065-443f-4d24-b85b-6ba0811e6414"
      },
      "source": [
        "#### stockage dans un fichier csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3b877f29-0209-45bc-b679-c03e25e8249a",
      "metadata": {
        "id": "3b877f29-0209-45bc-b679-c03e25e8249a"
      },
      "outputs": [],
      "source": [
        "def caption_dataset(img_paths, output_csv, img_folder=\"images\"):\n",
        "    \"\"\"\n",
        "    Génère un fichier CSV contenant les descriptions (captions) de toutes les images extraites.\n",
        "\n",
        "    Args:\n",
        "        img_paths (list): Liste des chemins relatifs des images (fichiers présents dans le dossier `img_folder`).\n",
        "        output_csv (str): Chemin du fichier CSV à créer pour stocker les résultats.\n",
        "        img_folder (str): Nom du dossier contenant les images (par défaut \"images\").\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Un DataFrame contenant deux colonnes :\n",
        "                      - 'image_filename': le nom du fichier image\n",
        "                      - 'caption': la description générée automatiquement\n",
        "    \"\"\"\n",
        "    data = []\n",
        "\n",
        "    for path in img_paths:\n",
        "        caption = generate_image_caption(\"images/\"+path)\n",
        "        data.append({\n",
        "            \"image_filename\": os.path.basename(path),\n",
        "            \"caption\": caption,\n",
        "        })\n",
        "        print(f\" {os.path.basename(path)} → {img_paths.index(path)} → {caption}\")\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
        "    print(f\"\\n CSV généré avec {len(df)} lignes :::: {output_csv}\")\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1799483-413c-4f38-b4fa-6eaa65fa7ed4",
      "metadata": {
        "id": "e1799483-413c-4f38-b4fa-6eaa65fa7ed4"
      },
      "outputs": [],
      "source": [
        "img_paths=os.listdir(\"images/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93633cad-2bf9-43e0-bfb2-7c7fbcd55854",
      "metadata": {
        "id": "93633cad-2bf9-43e0-bfb2-7c7fbcd55854",
        "outputId": "dce5e1d8-9f88-4f98-e11b-70313389b5fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 20240903-bnpparibas-csr-presentation-2024_page5_img1.png → 0 → a black and white image of a black and white image of a black and white image of a black and\n"
          ]
        }
      ],
      "source": [
        "caption_dataset(img_paths,\"caption_image.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6c13ead-d403-4a01-b338-8ad22564435a",
      "metadata": {
        "id": "b6c13ead-d403-4a01-b338-8ad22564435a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}